{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b42b28",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ¤– AI Data Copilot â€” Agent com RAG + Tools\n",
    "\n",
    "Projeto desenvolvido para demonstrar a construÃ§Ã£o de um **AI Agent com mÃºltiplas ferramentas**, combinando:\n",
    "\n",
    "ğŸ“š RAG (Retrievalâ€‘Augmented Generation)  \n",
    "ğŸŒ Busca Web em tempo real  \n",
    "ğŸ§® ExecuÃ§Ã£o de cÃ¡lculos via Python  \n",
    "ğŸ§  RaciocÃ­nio ReAct (Thought â†’ Action â†’ Observation)  \n",
    "\n",
    "O objetivo Ã© simular um **Copiloto de Dados e OperaÃ§Ãµes** capaz de responder perguntas estratÃ©gicas utilizando conhecimento interno + externo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e347aec",
   "metadata": {},
   "source": [
    "## ğŸ”‘ ConfiguraÃ§Ã£o da OpenAI API Key\n",
    "Antes de rodar, insira sua chave abaixo (nÃ£o compartilhe publicamente):\n",
    "\n",
    "Cole sua chave aqui para testar o projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c148e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"SUA_CHAVE_AQUI\"\n",
    "\n",
    "print(\"âœ… API Key configurada!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ef9f4",
   "metadata": {},
   "source": [
    "## ğŸ¤– Modelo LLM\n",
    "Carregando o modelo de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b433e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Modelo carregado!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99035e4b",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Imports e DependÃªncias\n",
    "Nesta etapa carregamos todas as bibliotecas utilizadas no projeto.\n",
    "\n",
    "ğŸ“š Bibliotecas principais do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57742782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "print(\"âœ… Imports carregados!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05127225",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Carregamento dos Documentos (Base RAG)\n",
    "Aqui carregamos documentos internos que servirÃ£o como base de conhecimento do Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ğŸ“‚ Carregando documentos...\")\n",
    "\n",
    "# ğŸ“„ Arquivos TXT\n",
    "txt1 = TextLoader(\"churn_regras.txt\", encoding=\"utf-8\").load()\n",
    "txt2 = TextLoader(\"faq_suporte.txt\", encoding=\"utf-8\").load()\n",
    "txt3 = TextLoader(\"kpi_definicoes.txt\", encoding=\"utf-8\").load()\n",
    "\n",
    "# ğŸ“‘ Arquivo PDF\n",
    "pdf = PyPDFLoader(\"sla_politica.pdf\").load()\n",
    "\n",
    "# ğŸ”— Unificando tudo\n",
    "documents = txt1 + txt2 + txt3 + pdf\n",
    "\n",
    "print(f\"âœ… Total de documentos: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535c8d0",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Chunking\n",
    "Dividimos os documentos em pedaÃ§os menores para melhorar a recuperaÃ§Ã£o semÃ¢ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(\"ğŸ§© Total de chunks:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19edab",
   "metadata": {},
   "source": [
    "## ğŸ§  Embeddings + FAISS\n",
    "Transformamos os textos em vetores e criamos o Ã­ndice vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "index_path = \"faiss_index\"\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "\n",
    "    print(\"ğŸ“‚ Carregando Ã­ndice existente...\")\n",
    "\n",
    "    vectorstore = FAISS.load_local(\n",
    "        index_path,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"ğŸ§  Criando novo Ã­ndice...\")\n",
    "\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        chunks,\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    vectorstore.save_local(index_path)\n",
    "\n",
    "    print(\"âœ… Ãndice salvo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd8507",
   "metadata": {},
   "source": [
    "## ğŸ” Retriever\n",
    "ResponsÃ¡vel por buscar os trechos mais relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "print(\"ğŸ” Retriever criado (Top 3)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa1467",
   "metadata": {},
   "source": [
    "## ğŸ§¾ Prompt Template\n",
    "Define como o modelo deve usar o contexto recuperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Responda usando exclusivamente o texto do contexto.\n",
    "\n",
    "- NÃ£o reescreva nÃºmeros.\n",
    "- NÃ£o arredonde valores.\n",
    "- NÃ£o complete informaÃ§Ãµes.\n",
    "\n",
    "Se nÃ£o houver dado exato, diga:\n",
    "\"InformaÃ§Ã£o nÃ£o encontrada na base.\"\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta:\n",
    "{question}\n",
    "\n",
    "Resposta literal:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637a880",
   "metadata": {},
   "source": [
    "## ğŸ”— QA Chain (RAG)\n",
    "Integra Retriever + Prompt + LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=False  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00331440",
   "metadata": {},
   "source": [
    "## ğŸ§° Tools do Agent\n",
    "Criamos ferramentas que o Agent pode utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§® Python Geral\n",
    "python_tool = Tool(\n",
    "    name=\"Python Geral\",\n",
    "    func=python_repl.run,\n",
    "    description=\"\"\"\n",
    "Use para cÃ¡lculos matemÃ¡ticos,\n",
    "estatÃ­sticos ou simulaÃ§Ãµes numÃ©ricas.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# ğŸŒ Web Tool\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "duckduckgo_tool = Tool(\n",
    "    name=\"Busca Web\",\n",
    "    func=search.run,\n",
    "    description=\"\"\"\n",
    "Use para buscar benchmarks de mercado,\n",
    "mÃ©tricas SaaS e melhores prÃ¡ticas.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# ğŸ“š RAG Tool\n",
    "rag_tool = Tool(\n",
    "    name=\"Base de Conhecimento\",\n",
    "    func=chain.run,\n",
    "    description=\"\"\"\n",
    "Use para consultar polÃ­ticas internas,\n",
    "SLA, churn e definiÃ§Ãµes de suporte.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ§° Tools carregadas!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381694b",
   "metadata": {},
   "source": [
    "## ğŸ¤– CriaÃ§Ã£o do Agent ReAct\n",
    "Aqui conectamos LLM + Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "react_prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    react_prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Agent pronto!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61980327",
   "metadata": {},
   "source": [
    "## ğŸ§ª Testes do Agent\n",
    "Perguntas para validar cada Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0781748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ğŸ§ª TESTES ORGANIZADOS DO AGENT\n",
    "# =========================\n",
    "\n",
    "testes = [\n",
    "\n",
    "    # ğŸ“š RAG\n",
    "    \"Qual Ã© o SLA para prioridade crÃ­tica?\",\n",
    "    \"Quando um cliente Ã© considerado churn?\",\n",
    "\n",
    "    # ğŸŒ Web\n",
    "    \"Qual Ã© o churn mÃ©dio em empresas SaaS?\",\n",
    "    \"Quais sÃ£o as melhores prÃ¡ticas de SLA?\",\n",
    "\n",
    "    # ğŸ§® Python\n",
    "    \"Qual Ã© 15% de 1200?\",\n",
    "    \"Se 8% de 500 tickets estÃ£o fora do SLA, quantos sÃ£o?\",\n",
    "\n",
    "    # ğŸ”€ Multi-tools\n",
    "    \"Quantos tickets crÃ­ticos tivemos e qual o SLA definido?\",\n",
    "    \"Nossa satisfaÃ§Ã£o estÃ¡ boa comparada ao mercado?\"\n",
    "]\n",
    "\n",
    "for pergunta in testes:\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"ğŸ§ª Pergunta: {pergunta}\")\n",
    "\n",
    "    resposta = agent_executor.invoke({\n",
    "        \"input\": pergunta\n",
    "    })\n",
    "\n",
    "    print(\"\\nğŸ§  Resposta:\")\n",
    "    print(resposta[\"output\"])\n",
    "    print(\"==============================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2a7fa",
   "metadata": {},
   "source": [
    "# ğŸ§ª Testes do Agent â€” Outputs de Resposta\n",
    "\n",
    "Esta seÃ§Ã£o demonstra exemplos reais de perguntas feitas ao Agent e suas respectivas respostas, validando o funcionamento das Tools integradas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45b5ce",
   "metadata": {},
   "source": [
    "## ğŸ“š RAG â€” Base de Conhecimento\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Qual Ã© o SLA para prioridade crÃ­tica?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "O SLA para prioridade crÃ­tica Ã© um tempo mÃ¡ximo de resoluÃ§Ã£o de atÃ© **24 horas**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Quando um cliente Ã© considerado churn?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "Um cliente Ã© considerado churn quando cancela sua assinatura ou deixa de renovar em um determinado perÃ­odo, contribuindo para a taxa de churn da empresa.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Web â€” Benchmarks de Mercado\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Qual Ã© o churn mÃ©dio em empresas SaaS?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "O churn mÃ©dio em empresas SaaS Ã© idealmente abaixo de **2% ao mÃªs**, enquanto taxas acima de **5%** podem impactar negativamente o crescimento.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Quais sÃ£o as melhores prÃ¡ticas de SLA?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "As melhores prÃ¡ticas de SLA incluem:\n",
    "\n",
    "- DefiniÃ§Ã£o clara de objetivos e metas  \n",
    "- Monitoramento contÃ­nuo  \n",
    "- ComunicaÃ§Ã£o eficaz  \n",
    "- RevisÃµes periÃ³dicas do acordo  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® Python Tool â€” CÃ¡lculos\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Qual Ã© 15% de 1200?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "15% de 1200 Ã© **180**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Se 8% de 500 tickets estÃ£o fora do SLA, quantos sÃ£o?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "8% de 500 tickets correspondem a **40 tickets** fora do SLA.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”€ Multiâ€‘Tools â€” RaciocÃ­nio HÃ­brido\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Quantos tickets crÃ­ticos tivemos e qual o SLA definido?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "O SLA para tickets crÃ­ticos Ã© de atÃ© **24 horas para resoluÃ§Ã£o**.  \n",
    "(O total de tickets crÃ­ticos depende da base analÃ­tica conectada.)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª Pergunta\n",
    "**Nossa satisfaÃ§Ã£o estÃ¡ boa comparada ao mercado?**\n",
    "\n",
    "### ğŸ§  Resposta\n",
    "Para avaliar competitividade, Ã© necessÃ¡rio comparar mÃ©tricas como **CSAT** e **NPS** com benchmarks do setor.  \n",
    "Benchmarks indicam que empresas SaaS de alto desempenho mantÃªm CSAT acima de **4.0/5** e NPS positivo.\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… ConclusÃ£o dos Testes\n",
    "\n",
    "Os testes validam que o Agent consegue:\n",
    "\n",
    "- ğŸ“š Consultar documentos internos (RAG)\n",
    "- ğŸŒ Buscar benchmarks externos\n",
    "- ğŸ§® Executar cÃ¡lculos via Python\n",
    "- ğŸ”€ Combinar mÃºltiplas fontes\n",
    "\n",
    "Demonstrando raciocÃ­nio autÃ´nomo com Tools."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
